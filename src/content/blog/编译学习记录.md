---
title: 编译学习笔记
description: 学习编译过程中的记录
pubDate: 2025-9-10
image: /image/compliers.jpg
categories:
  - tech
tags:
  - 编译器
  - compliers
  - 学习笔记
---

## 前言

本篇博客主要记录我学习 complier 的过程.
主要参考实验:[PKU编译原理实验](https://pku-minic.github.io/online-doc/#/)
主要参考书籍: 《编译器设计(第二版)》 《编译方法、技术与实践》

## 正文

### 9-10

#### Lv0. 环境配置

记录一下上一周完成的：根据北大编译实验在线文档完成了Lv0.环境配置
配置了docker源，并且根据docker写了一个启动脚本，我选择了c/c++路线使用cmake进行编译。

#### Lv1. main函数

##### Lv1.1. 编译器的结构

编译器通常由以下几个部分组成:

- 前端: 通过词法分析和语法分析, 将源代码解析成抽象语法树 (abstract syntax tree, AST). 通过语义分析, 扫描抽象语法树, 检查其是否存在语义错误.
- 中端: 将抽象语法树转换为中间表示 (intermediate representation, IR), 并在此基础上完成一些机器无关优化.
- 后端: 将中间表示转换为目标平台的汇编代码, 并在此基础上完成一些机器相关优化.

一些英文用语

- 词法分析器（lexer）
- 语法分析器（parser）
- 字节流（byte stream）
- 单词流（token stream）

词法分析的作用, 是把字节流转换为单词流 (token stream).
语法分析的目的, 按照程序的语法规则, 将输入的 token 流变成程序的 AST.
在语法分析的基础上, 编译器会对 AST 做进一步分析, 以期 “理解” 输入程序的语义, 为之后的 IR 生成做准备.
编译器通常会将 AST 转换为另一种形式的数据结构, 我们把它称作 IR. IR 的抽象层次比 AST 更低, 但又不至于低到汇编代码的程度. 在此基础上, 无论是直接把 IR 进一步转换为汇编代码, 还是在 IR 之上做出一些优化, 都相对更容易.（比较出名的LLVM 里面就有很多IR）
编译器进行的最后一步操作, 就是将 IR 转换为目标代码, 也就是目标指令系统的汇编代码.

##### Lv1.2. 语法/词法分析初见

由于生在一个好时代，我们想要实现一个效率蛮不错的词法/语法分析器，并不需要手写递归下降分析器。不过我先在这里放一个网址，可以以后留着来看 [Kaleidoscope](https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.html).
现在的工具可以根据正则表达式和 EBNF 生成词法/语法分析器.

EBNF, 即 [Extended Backus–Naur Form](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form), 扩展巴科斯范式, 可以用来描述编程语言的语法.